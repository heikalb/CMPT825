{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Phrasal Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your documentation for the chunker homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data ...\n",
      "done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #: 0\n",
      "Correctly identified: 195245\n",
      "Number of mistakes: 16482\n",
      "Epoch #: 1\n",
      "Correctly identified: 202691\n",
      "Number of mistakes: 9036\n",
      "Epoch #: 2\n",
      "Correctly identified: 205586\n",
      "Number of mistakes: 6141\n",
      "Epoch #: 3\n",
      "Correctly identified: 207445\n",
      "Number of mistakes: 4282\n",
      "Epoch #: 4\n",
      "Correctly identified: 208458\n",
      "Number of mistakes: 3269\n",
      "Epoch #: 5\n",
      "Correctly identified: 209159\n",
      "Number of mistakes: 2568\n",
      "Epoch #: 6\n",
      "Correctly identified: 209622\n",
      "Number of mistakes: 2105\n",
      "Epoch #: 7\n",
      "Correctly identified: 210159\n",
      "Number of mistakes: 1568\n",
      "Epoch #: 8\n",
      "Correctly identified: 210292\n",
      "Number of mistakes: 1435\n",
      "Epoch #: 9\n",
      "Correctly identified: 210554\n",
      "Number of mistakes: 1173\n",
      "wrote model to disk\n",
      "CPU times: user 3h 15min 46s, sys: 46.1 s, total: 3h 16min 32s\n",
      "Wall time: 6h 41min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import perc\n",
    "import default\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "feat_vec = {}\n",
    "tagset = []\n",
    "train_data = []\n",
    "\n",
    "def perc_train(train_data, tagset, numepochs):\n",
    "    count = 0 \n",
    "    feat_vec = defaultdict(int)\n",
    "    new_feat_vec = defaultdict(float)\n",
    "    for epoch in range(numepochs):\n",
    "        print(\"Epoch #:\", epoch)\n",
    "        positives = 0\n",
    "        negatives = 0\n",
    "        for data in train_data:\n",
    "            words = []\n",
    "            chunks = []\n",
    "            text = data[0] #in IN B-PP\n",
    "            feat = data[1] #U01:_B-1\n",
    "            for info in text:\n",
    "                (word, pos, chunk) = info.split()\n",
    "                words.append(word) \n",
    "                chunks.append(chunk)\n",
    "            tag0 = tagset[0]\n",
    "            # Get the output tags for the input sentence\n",
    "            output_tags = perc.perc_test(feat_vec=feat_vec, \n",
    "                                         labeled_list=text, \n",
    "                                         feat_list=feat, \n",
    "                                         tagset=tagset, \n",
    "                                         default_tag=tag0)\n",
    "            feat_index = 0\n",
    "            counter = 0\n",
    "            #If chunking tag is incorrect, decrease the feature vector weight by 1; Increase negative count by 1\n",
    "            #Increase the weight by 1 for every correct tag. Increment positive counter by 1 \n",
    "            for word in words:\n",
    "                (feat_index, feats) = perc.feats_for_word(feat_index, feat_list=feat)\n",
    "                tag = output_tags[counter]\n",
    "                best_tag = chunks[counter]\n",
    "                if (tag == best_tag):\n",
    "                    counter +=1\n",
    "                    continue\n",
    "                for ft in feats:\n",
    "                    correct = ft, best_tag\n",
    "                    incorrect = ft, tag\n",
    "                    feat_vec[correct] += 1\n",
    "                    feat_vec[incorrect] -= 1\n",
    "                counter += 1\n",
    "            counter = 0\n",
    "            \n",
    "            for word in words:\n",
    "                tag = output_tags[counter]\n",
    "                best_tag = chunks[counter]\n",
    "                if (tag == best_tag):\n",
    "                    counter += 1\n",
    "                    positives += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    negatives += 1\n",
    "\n",
    "                prev_value = \"B:\"\n",
    "                prev_tag = \"B:\"\n",
    "                if (counter == 0):\n",
    "                    prev_value += \"_B-1\"\n",
    "                    prev_tag += \"_B-1\"   \n",
    "                else:\n",
    "                    prev_value += chunks[counter - 1]\n",
    "                    prev_tag += output_tags[counter - 1]\n",
    "                correct = prev_value, best_tag\n",
    "                incorrect = prev_tag, tag\n",
    "                feat_vec[correct] += 1\n",
    "                feat_vec[incorrect] -= 1\n",
    "                counter += 1\n",
    "\n",
    "            for key in feat_vec.keys():\n",
    "                new_feat_vec[key] += feat_vec[key]\n",
    "            count+=1\n",
    "\n",
    "        print(\"Correctly identified:\", positives)\n",
    "        print(\"Number of mistakes:\", negatives)\n",
    "\n",
    "    for key in new_feat_vec.keys():\n",
    "        new_feat_vec[key] = new_feat_vec[key]/float(count)\n",
    "    return new_feat_vec\n",
    "\n",
    "\n",
    "tagset = perc.read_tagset(\"data/tagset.txt\")\n",
    "print(\"reading data ...\", file=sys.stderr)\n",
    "train_data = perc.read_labeled_data(\"data/train.txt.gz\", \"data/train.feats.gz\", verbose=False)\n",
    "print(\"done.\", file=sys.stderr)\n",
    "feat_vec = perc_train(train_data, tagset, 10)\n",
    "perc.perc_write_to_file(feat_vec, \"default.model\")\n",
    "print(\"wrote model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading test data ...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr output\n",
    "print(\"reading test data ...\", file=sys.stderr)\n",
    "test_data = perc.read_labeled_data(\"data/dev.txt\", \"data/dev.feats\", verbose=False)\n",
    "print(\"done.\", file=sys.stderr)\n",
    "feat_vec = perc.perc_read_from_file(\"default.model\")\n",
    "perc.perc_testall(feat_vec, test_data, tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 500 sentences with 10375 tokens and 5783 phrases; found phrases: 5790; correct phrases: 5407\n",
      "             ADJP: precision:  73.47%; recall:  72.73%; F1:  73.10; found:     98; correct:     99\n",
      "             ADVP: precision:  77.29%; recall:  79.21%; F1:  78.24; found:    207; correct:    202\n",
      "            CONJP: precision: 100.00%; recall:  60.00%; F1:  75.00; found:      3; correct:      5\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; F1:   0.00; found:      0; correct:      1\n",
      "               NP: precision:  94.24%; recall:  94.02%; F1:  94.13; found:   3019; correct:   3026\n",
      "               PP: precision:  96.92%; recall:  97.95%; F1:  97.43; found:   1234; correct:   1221\n",
      "              PRT: precision:  80.00%; recall:  72.73%; F1:  76.19; found:     20; correct:     22\n",
      "             SBAR: precision:  84.76%; recall:  83.18%; F1:  83.96; found:    105; correct:    107\n",
      "               VP: precision:  92.93%; recall:  93.27%; F1:  93.10; found:   1104; correct:   1100\n",
      "accuracy:  95.52%; precision:  93.39%; recall:  93.50%; F1:  93.44\n",
      "Score: 93.44\n"
     ]
    }
   ],
   "source": [
    "import score_chunks\n",
    "boundary = \"-X-\" # something to use as boundary between sentences\n",
    "outside = \"O\" # tag used to mark the outside of any chunk\n",
    "conlleval = False # use conlleval (should be False for most use cases)\n",
    "numfeats = 2 # number of columns to consider as features, typically \"word POStag\"\n",
    "(test, _) = score_chunks.readTestFile(str(output), boundary, outside, conlleval, numfeats)\n",
    "with open(\"data/reference500.txt\") as f:\n",
    "    (reference, _) = score_chunks.readTestFile(f.read(), boundary, outside, conlleval, numfeats)\n",
    "print(\"Score: %.2f\" % score_chunks.corpus_fmeasure(reference, test, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data ...\n",
      "done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #: 0\n",
      "Correctly identified: 195245\n",
      "Number of mistakes: 16482\n",
      "Epoch #: 1\n",
      "Correctly identified: 202691\n",
      "Number of mistakes: 9036\n",
      "Epoch #: 2\n",
      "Correctly identified: 205586\n",
      "Number of mistakes: 6141\n",
      "Epoch #: 3\n",
      "Correctly identified: 207445\n",
      "Number of mistakes: 4282\n",
      "Epoch #: 4\n",
      "Correctly identified: 208458\n",
      "Number of mistakes: 3269\n",
      "wrote model to disk\n",
      "CPU times: user 1h 23min 5s, sys: 24.5 s, total: 1h 23min 29s\n",
      "Wall time: 1h 24min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import perc\n",
    "import default\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "feat_vec = {}\n",
    "tagset = []\n",
    "train_data = []\n",
    "\n",
    "def perc_train(train_data, tagset, numepochs):\n",
    "    count = 0 \n",
    "    feat_vec = defaultdict(int)\n",
    "    new_feat_vec = defaultdict(float)\n",
    "    for epoch in range(numepochs):\n",
    "        print(\"Epoch #:\", epoch)\n",
    "        positives = 0\n",
    "        negatives = 0\n",
    "        for data in train_data:\n",
    "            words = []\n",
    "            chunks = []\n",
    "            text = data[0] #in IN B-PP\n",
    "            feat = data[1] #U01:_B-1\n",
    "            for info in text:\n",
    "                (word, pos, chunk) = info.split()\n",
    "                words.append(word) \n",
    "                chunks.append(chunk)\n",
    "            tag0 = tagset[0]\n",
    "            \n",
    "            output_tags = perc.perc_test(feat_vec=feat_vec, \n",
    "                                         labeled_list=text, \n",
    "                                         feat_list=feat, \n",
    "                                         tagset=tagset, \n",
    "                                         default_tag=tag0)\n",
    "            feat_index = 0\n",
    "            counter = 0\n",
    "\n",
    "            for word in words:\n",
    "                (feat_index, feats) = perc.feats_for_word(feat_index, feat_list=feat)\n",
    "                tag = output_tags[counter]\n",
    "                best_tag = chunks[counter]\n",
    "                if (tag == best_tag):\n",
    "                    counter +=1\n",
    "                    continue\n",
    "                for ft in feats:\n",
    "                    correct = ft, best_tag\n",
    "                    incorrect = ft, tag\n",
    "                    feat_vec[correct] += 1\n",
    "                    feat_vec[incorrect] -= 1\n",
    "                counter += 1\n",
    "            counter = 0\n",
    "            \n",
    "            for word in words:\n",
    "                tag = output_tags[counter]\n",
    "                best_tag = chunks[counter]\n",
    "                if (tag == best_tag):\n",
    "                    counter += 1\n",
    "                    positives += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    negatives += 1\n",
    "\n",
    "                prev_value = \"B:\"\n",
    "                prev_tag = \"B:\"\n",
    "                if (counter == 0):\n",
    "                    prev_value += \"_B-1\"\n",
    "                    prev_tag += \"_B-1\"   \n",
    "                else:\n",
    "                    prev_value += chunks[counter - 1]\n",
    "                    prev_tag += output_tags[counter - 1]\n",
    "                correct = prev_value, best_tag\n",
    "                incorrect = prev_tag, tag\n",
    "                feat_vec[correct] += 1\n",
    "                feat_vec[incorrect] -= 1\n",
    "                counter += 1\n",
    "\n",
    "            for key in feat_vec.keys():\n",
    "                new_feat_vec[key] += feat_vec[key]\n",
    "            count+=1\n",
    "\n",
    "        print(\"Correctly identified:\", positives)\n",
    "        print(\"Number of mistakes:\", negatives)\n",
    "\n",
    "    for key in new_feat_vec.keys():\n",
    "        new_feat_vec[key] = new_feat_vec[key]/float(count)\n",
    "    return new_feat_vec\n",
    "\n",
    "\n",
    "tagset = perc.read_tagset(\"data/tagset.txt\")\n",
    "print(\"reading data ...\", file=sys.stderr)\n",
    "train_data = perc.read_labeled_data(\"data/train.txt.gz\", \"data/train.feats.gz\", verbose=False)\n",
    "print(\"done.\", file=sys.stderr)\n",
    "feat_vec = perc_train(train_data, tagset, 5)\n",
    "perc.perc_write_to_file(feat_vec, \"default.model\")\n",
    "print(\"wrote model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading test data ...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr output\n",
    "print(\"reading test data ...\", file=sys.stderr)\n",
    "test_data = perc.read_labeled_data(\"data/dev.txt\", \"data/dev.feats\", verbose=False)\n",
    "print(\"done.\", file=sys.stderr)\n",
    "feat_vec = perc.perc_read_from_file(\"default.model\")\n",
    "perc.perc_testall(feat_vec, test_data, tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 500 sentences with 10375 tokens and 5783 phrases; found phrases: 5796; correct phrases: 5399\n",
      "             ADJP: precision:  71.13%; recall:  69.70%; F1:  70.41; found:     97; correct:     99\n",
      "             ADVP: precision:  76.70%; recall:  78.22%; F1:  77.45; found:    206; correct:    202\n",
      "            CONJP: precision: 100.00%; recall:  60.00%; F1:  75.00; found:      3; correct:      5\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; F1:   0.00; found:      0; correct:      1\n",
      "               NP: precision:  94.08%; recall:  93.99%; F1:  94.03; found:   3023; correct:   3026\n",
      "               PP: precision:  96.93%; recall:  98.12%; F1:  97.52; found:   1236; correct:   1221\n",
      "              PRT: precision:  75.00%; recall:  68.18%; F1:  71.43; found:     20; correct:     22\n",
      "             SBAR: precision:  83.96%; recall:  83.18%; F1:  83.57; found:    106; correct:    107\n",
      "               VP: precision:  92.58%; recall:  93.00%; F1:  92.79; found:   1105; correct:   1100\n",
      "accuracy:  95.35%; precision:  93.15%; recall:  93.36%; F1:  93.26\n",
      "Score: 93.26\n"
     ]
    }
   ],
   "source": [
    "import score_chunks\n",
    "boundary = \"-X-\" # something to use as boundary between sentences\n",
    "outside = \"O\" # tag used to mark the outside of any chunk\n",
    "conlleval = False # use conlleval (should be False for most use cases)\n",
    "numfeats = 2 # number of columns to consider as features, typically \"word POStag\"\n",
    "(test, _) = score_chunks.readTestFile(str(output), boundary, outside, conlleval, numfeats)\n",
    "with open(\"data/reference500.txt\") as f:\n",
    "    (reference, _) = score_chunks.readTestFile(f.read(), boundary, outside, conlleval, numfeats)\n",
    "print(\"Score: %.2f\" % score_chunks.corpus_fmeasure(reference, test, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
