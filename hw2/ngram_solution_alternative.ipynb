{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from ngram import *\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# ngram model for scoring hypotheses\n",
    "ngram_model = LM(\"data/6-gram-wiki-char.lm.bz2\", n=8, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "def beam_search(plaintext_alph, cipher_text, ext_order, ext_limits, beam_size=1):\n",
    "\n",
    "    scored_hypotheses = [(0, [])]\n",
    "    hypothesis_extensions = []\n",
    "   \n",
    "    num_symbols = len(ext_order)\n",
    "        \n",
    "    while ext_order:\n",
    "        \n",
    "        cipher_sym = ext_order[0]\n",
    "        ext_order.remove(cipher_sym)\n",
    "        \n",
    "        for hyp in scored_hypotheses:\n",
    "            for pl_sym in plaintext_alph:\n",
    "                new_hypothesis = hyp[1] + [(pl_sym, cipher_sym)]\n",
    "                if within_ext_limits(ext_limits, new_hypothesis):\n",
    "                    hypothesis_extensions.append((score(new_hypothesis, cipher_text), new_hypothesis,))\n",
    "\n",
    "        if  hypothesis_extensions:\n",
    "            hypothesis_extensions = histogram_prune(hypothesis_extensions, 80)\n",
    "            scored_hypotheses = [h for h in hypothesis_extensions]\n",
    "         \n",
    "        decipherment = ''.join([g_funct(scored_hypotheses[0][1], ch) for ch in cipher_text])\n",
    "        bitstring = ''\n",
    "        for ch in decipherment:\n",
    "            if ch == '_':\n",
    "                bitstring += '.'\n",
    "            else:\n",
    "                bitstring += 'o'\n",
    "\n",
    "        if len(ext_order) > 0:\n",
    "            ext_order = update_ext_order(cipher_text, bitstring)\n",
    "\n",
    "        hypothesis_extensions.clear()\n",
    "        \n",
    "    return winning_hypothesis(scored_hypotheses) \n",
    "\n",
    "def get_max_n_gram(cipher_map):\n",
    "    max_n_gram = 0\n",
    "    n_gram = 0\n",
    "    for i in range(len(cipher_map)):\n",
    "        if cipher_map[i] != '.':\n",
    "            n_gram += 1\n",
    "        else:\n",
    "            max_n_gram = max(max_n_gram,n_gram)\n",
    "            n_gram = 0\n",
    "    return max_n_gram\n",
    "\n",
    "def update_ext_order(cipher_text, bitstring):\n",
    "\n",
    "    max_n_gram_allowed = 6\n",
    "    # weights assuming n-gram = 6\n",
    "    ngram_weights = [1.0,1.0,1.0,1.0,2.0,3.0] \n",
    "    \n",
    "    max_n_gram = get_max_n_gram(bitstring)\n",
    "\n",
    "    non_mapped_positions = [(x[1],x[2]) for x in [x for x in zip([x for x in bitstring],\n",
    "                                                                 [i for i in cipher_text],\n",
    "                                                                 [i for i in range(len(cipher_text))]) if x[0] == '.']]\n",
    "\n",
    "    non_mapped_symbols = list(set([x[1] for x in [x for x in zip([x for x in bitstring],\n",
    "                                                                 [x for x in cipher_text]) if x[0] == '.']]))\n",
    "\n",
    "    main_dict = dict()\n",
    "    for symbol in non_mapped_symbols:\n",
    "\n",
    "        symbol_dict = dict()\n",
    "        for n_gram in range(1, max_n_gram_allowed+1):\n",
    "            symbol_dict[n_gram] = 0\n",
    "\n",
    "        positions = [x[1] for x in non_mapped_positions if x[0]==symbol]\n",
    "        for pos in positions:\n",
    "\n",
    "            left_neighbors = len(bitstring[:pos].split('.')[-1])\n",
    "            for i in range(min(left_neighbors,max_n_gram_allowed)):\n",
    "                symbol_dict[i+1]+=1\n",
    "\n",
    "            right_neighbors = len(bitstring[pos+1:].split('.')[0])\n",
    "            for i in range(min(right_neighbors,max_n_gram_allowed)):\n",
    "                symbol_dict[i+1]+=1\n",
    "        main_dict[symbol] = symbol_dict\n",
    "\n",
    "    symbol_scores = []\n",
    "\n",
    "    for symbol in main_dict.keys():\n",
    "        score = 0\n",
    "        for ngram in range(1,min(max_n_gram,6)):\n",
    "            score += ngram_weights[ngram-1] * main_dict[symbol][ngram]\n",
    "        symbol_scores.append((symbol,score))\n",
    "\n",
    "    return [x[0] for x in sorted(symbol_scores, key=lambda tup: tup[1],reverse=True)]\n",
    "    \n",
    "    \n",
    "def score(hypothesis, text):\n",
    "    decipherment = ''.join([g_funct(hypothesis, ch) for ch in text])\n",
    "    bitstring = ''\n",
    "    for ch in decipherment:\n",
    "        if ch == '_':\n",
    "            bitstring += '.'\n",
    "        else:\n",
    "            bitstring += 'o'\n",
    "    \n",
    "    #return ngram_model.score_seq(decipherment)\n",
    "    return ngram_model.score_bitstring(decipherment, bitstring)\n",
    "\n",
    "\n",
    "# Helper function for score(). Returns plaintext string for a cipher symbol given a hypothesized mapping\n",
    "def g_funct(hypothesis, cipher_sym):\n",
    "    for tup in hypothesis:\n",
    "        if tup[1] == cipher_sym:\n",
    "            return tup[0]\n",
    "    return '_'\n",
    "\n",
    "# Chooses the best scoring hypothesis\n",
    "def histogram_prune(hypotheses, n=1):\n",
    "    hypotheses.sort()\n",
    "    return hypotheses[-n:]\n",
    "\n",
    "\n",
    "# Pick the best hypothesis\n",
    "def winning_hypothesis(hypotheses):\n",
    "    return histogram_prune(hypotheses, 1)[0][1]\n",
    "\n",
    "\n",
    "def within_ext_limits(ext_limits, hyp):\n",
    "    plaintxt_sym_counter = Counter([tup[0] for tup in hyp])\n",
    "    return not [k for k in plaintxt_sym_counter if plaintxt_sym_counter[k] > ext_limits[k]]\n",
    "\n",
    "# Get an extension order based on contiguous deciphered ngrams\n",
    "# This is used to pick the first \n",
    "def get_ext_order(alphabet, cipher):\n",
    "    ext_order = [alphabet[0]]\n",
    "    alphabet.pop(0)\n",
    "\n",
    "    while alphabet:\n",
    "        max_sum = weighted_sum(alphabet[0], cipher, ext_order)\n",
    "        max_char = alphabet[0]\n",
    "\n",
    "        for a in alphabet[1:]:\n",
    "            curr_sum = weighted_sum(a, cipher, ext_order)\n",
    "\n",
    "            if curr_sum > max_sum:\n",
    "                max_sum = curr_sum\n",
    "                max_char = a\n",
    "        \n",
    "        ext_order.append(max_char)\n",
    "        alphabet.remove(max_char)\n",
    "    \n",
    "    return ext_order\n",
    "\n",
    "# Calculate the weighted sum for ext order candidates\n",
    "def weighted_sum(ch, cipher, ext_order):\n",
    "    sum = 0\n",
    "    for n in range(2, 7):\n",
    "        grams = [g for g in ngrams(cipher, n) if all(c in ext_order + [ch] for c in g)]\n",
    "        sum += len(grams)*n\n",
    "\n",
    "    return sum    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher = read_file(\"data/cipher.txt\").replace('\\n', '')\n",
    "plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "\n",
    "# Cipher and plaintext alphabets\n",
    "cipher_count = Counter([ch for ch in cipher if not ch == '\\n'])\n",
    "ext_order = [tup[0] for tup in cipher_count.most_common()]\n",
    "ext_order = get_ext_order(ext_order, cipher)\n",
    "eng_alphabet = [ch for ch in 'abcdefghijklmnopqrstuvwxyz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 6\n",
    "ext_limit = {'e': e, 't': e, 'a': e, 'o': e, 'i': e, 'n': e, 's': e, 'h': e,'r': e, 'd': e, \n",
    "              'l': e, 'c': e, 'u': e, 'm': e, 'w': e, 'f': e, 'g': e, 'y': e, 'p': e, 'b': e,\n",
    "              'v': e, 'k': e, 'j': e, 'x': e, 'q': e, 'z': e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hypothesis = beam_search(eng_alphabet, cipher, ext_order, ext_limit, beam_size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', '—'), ('t', '§'), ('e', 'Z'), ('e', 'I'), ('e', 'u'), ('r', 'W'), ('e', 'V'), ('r', '∞'), ('s', 'E'), ('t', 'X'), ('a', '≈'), ('t', 'H'), ('r', 'M'), ('a', 'º'), ('s', '“'), ('a', '£'), ('n', '–'), ('s', 'K'), ('h', '•'), ('s', 'B'), ('s', '∑'), ('e', 'P'), ('h', 'A'), ('t', 'À'), ('s', 'D'), ('o', 'R'), ('i', 'G'), ('r', '+'), ('i', 'π'), ('t', 'y'), ('o', 'F'), ('t', 'Ç'), ('n', '∏'), ('h', 'æ'), ('a', '√'), ('r', 'µ'), ('d', 'O'), ('n', '∫'), ('a', 'T'), ('a', 'Q'), ('i', 'J'), ('n', '‘'), ('o', 'L'), ('m', '^'), ('i', 'S'), ('n', 'ƒ'), ('l', '/'), ('o', '\\\\'), ('d', 'N'), ('r', 'Ã'), ('d', '¢'), ('l', 'Ω'), ('d', '∆'), ('c', 'j')]\n",
      "anelelesntdohnthsreraitorateistetaritmeetleandatsraidlassedohendorestmoreinsonoterahtireisasearethrtidodnetsrdheisaaissonlessitestremootaesenearethrorsassesorchroddasettoeandererrnoarmorteasonatsonalitiaherrhoennoadessthisetitrahorrdhaedetenthasseroreandemhisrdearlstinnerdtaiaslannedhessenaterenoshariahasndaroearnntenmiereeaitssnathansonnttostatthsnolothenanssraredotaoniaeiianenhierssearrestsarerestraheet\n"
     ]
    }
   ],
   "source": [
    "decipherment = ''.join([g_funct(best_hypothesis, ch) for ch in cipher])\n",
    "\n",
    "print(best_hypothesis)\n",
    "print(decipherment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
