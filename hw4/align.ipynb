{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4: Word Alignment\n",
    "\n",
    "Group: northernwolfpack\n",
    "\n",
    "Members:\n",
    "\n",
    "Heikal Badrulhisham (hbadrulh)\n",
    "\n",
    "Chithra Bhat (cbhat)\n",
    "\n",
    "Gustavo Felhberg (gfelhber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optparse, sys, os, logging\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training algorithm for the alignment model. The only improvement over the baseline that was kept was add-n smoothing. Adding null words to source sentences (add_null_words( )) could not be made to result in an improvement. The training algorithm could be halted if there is convergence but this was not implemented because convergence happens in the limit. there_is_convergence( ) is left here to display a theoretical addition to the training algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the word alignment model\n",
    "def train_alignment(bitext, iterations=1):\n",
    "    # Probabilities of word translation pairs\n",
    "    probs = defaultdict(defaultdict)\n",
    "    probs[0] = initialize_probs(bitext)\n",
    "\n",
    "    # Add null words into each source sentence\n",
    "    # add_null_words(bitext, probs[0])\n",
    "\n",
    "    f_vocab = list(set([word_f for [sent_f, sent_e] in bitext for word_f in sent_f]))\n",
    "\n",
    "    for k in range(1, iterations+1):\n",
    "        # Expected counts\n",
    "        count = defaultdict(float)\n",
    "        count_e = defaultdict(float)\n",
    "\n",
    "        # Update counts\n",
    "        for (sent_f, sent_e) in bitext:\n",
    "            for w_f in sent_f:\n",
    "                Z = 0\n",
    "\n",
    "                for w_e in sent_e:\n",
    "                    Z += probs[k-1][(w_f, w_e)]\n",
    "\n",
    "                for w_e in sent_e:\n",
    "                    c = probs[k-1][(w_f, w_e)]/Z\n",
    "                    count[(w_f, w_e)] = count[(w_f, w_e)] + c\n",
    "                    count_e[w_e] = count_e[w_e] + c\n",
    "\n",
    "        # Update probabilities\n",
    "        probs[k] = defaultdict()\n",
    "        for (w_f, w_e) in count:\n",
    "            # Smoothed probability\n",
    "            probs[k][(w_f, w_e)] = (count[(w_f, w_e)]+0.005)/(count_e[w_e] + len(f_vocab)*0.005)\n",
    "\n",
    "        # Stop upon convergence\n",
    "        # if thereis_convergence():\n",
    "        #     break\n",
    "\n",
    "    return probs[iterations]\n",
    "\n",
    "\n",
    "# TODO: tells if the update is converging\n",
    "def thereis_convergence():\n",
    "    return False\n",
    "\n",
    "# Add a null word in every source sentence\n",
    "def add_null_words(bitext, probs):\n",
    "    all_words_f = len([w for pair in bitext for w in pair[0]])\n",
    "\n",
    "    for pair in bitext:\n",
    "        pair[1].append('<Null>')\n",
    "\n",
    "        for w_f in pair[0]:\n",
    "            # Multiplied by a constant to simulate multiple null words per sentence\n",
    "            probs[(w_f, '<Null>')] += 7/all_words_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are different initialization methods for the t parameter.\n",
    "The first _initialize_probs() is the baseline initialization.\n",
    "The second _initialize_probs() is initialization by loglikelihood-ratio (LLR).\n",
    "llr_score() is a helper method for (second) initialize_probs(), which calculates the LLR of a given pair of words.\n",
    "get_occurrences() associates each word with the indices of sentences where it occurs. This enabled a faster initialization by LLR by avoiding the need to iterate through all the words in the dataset for each t(.|.).\n",
    "initialize_probs is a new heuristic that was devised which initializes t only for word pairs that co-occur in the same translation pair. This was found to be faster than the other initialization methods, and yielded results not too far behind initialization by LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the probabilities of word translation pairs uniformly. (Baseline initialization)\n",
    "def _initialize_probs(bitext):\n",
    "    probs = defaultdict(float)\n",
    "    f_vocab = list(set([word_f for [sent_f, sent_e] in bitext for word_f in sent_f]))\n",
    "    e_vocab = list(set([word_e for [sent_f, sent_e] in bitext for word_e in sent_e]))\n",
    "\n",
    "    for w_f in f_vocab:\n",
    "        for w_e in e_vocab:\n",
    "            probs[(w_f, w_e)] = 1/len(f_vocab)\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "# Similar to baseline initialization but only words that co-occur in translation pairs are given above zero\n",
    "# probabilities. Using this, training is faster and better than the baseline.\n",
    "def initialize_probs(bitext):\n",
    "    probs = defaultdict(float)\n",
    "    sum_by_word = defaultdict(int)\n",
    "\n",
    "    for sent_f, sent_e in bitext:\n",
    "        for w_f in sent_f:\n",
    "            for w_e in sent_e:\n",
    "                probs[(w_f, w_e)] += 1\n",
    "                sum_by_word[w_e] += 1\n",
    "\n",
    "    max_sum = sum_by_word[max(sum_by_word, key=sum_by_word.get)]\n",
    "\n",
    "    for p in probs:\n",
    "        probs[p] = probs[p]/max_sum\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "# Initialize the probabilities of word translation pairs with LLR scores\n",
    "def _initialize_probs(bitext):\n",
    "    probs = defaultdict(float)\n",
    "    f_vocab = list(set([word_f for [sent_f, sent_e] in bitext for word_f in sent_f]))\n",
    "    e_vocab = list(set([word_e for [sent_f, sent_e] in bitext for word_e in sent_e]))\n",
    "\n",
    "    # Indices of translation pairs where each word occurs\n",
    "    occurrences = get_occurrences(bitext)\n",
    "\n",
    "    # Keep track of source word with the largest LLR sum\n",
    "    llr_sums = defaultdict(float)\n",
    "\n",
    "    # Get LLR score for each target word\n",
    "    for w_e in e_vocab:\n",
    "        for w_f in f_vocab:\n",
    "            probs[(w_f, w_e)] = llr_score(w_f, w_e, bitext, occurrences)\n",
    "            llr_sums[w_e] += probs[(w_f, w_e)]\n",
    "\n",
    "    # Normalize by largest sum\n",
    "    max_llr_sum = llr_sums[max(llr_sums, key=llr_sums.get)]\n",
    "\n",
    "    for p in probs:\n",
    "        probs[p] = probs[p]/max_llr_sum\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "# Returns an LLR score\n",
    "def llr_score(trans, source, bitext, occurrences):\n",
    "    trans_s = occurrences[trans]\n",
    "    source_s = occurrences[source]\n",
    "\n",
    "    # counts of co-occurrence or non-co-occurrence of translation and source words in a translation pair\n",
    "    c_yy = len([s for s in source_s if s in trans_s])\n",
    "    c_ny = len([s for s in source_s if s not in trans_s])\n",
    "    c_yn = len([s for s in trans_s if s not in source_s])\n",
    "    c_nn = len(bitext) - c_yy - c_ny - c_yn\n",
    "\n",
    "    # Avoid math domain error\n",
    "    if c_yy == 0:\n",
    "        c_yy += 1\n",
    "    if c_ny == 0:\n",
    "        c_ny += 1\n",
    "    if c_yn == 0:\n",
    "        c_yn += 1\n",
    "    if c_nn == 0:\n",
    "        c_nn += 1\n",
    "\n",
    "    # Probabilities of absence/presence combinations\n",
    "    condprob_yy = c_yy/(c_yy + c_ny)\n",
    "    condprob_ny = c_ny/(c_ny + c_yy)\n",
    "    condprob_yn = c_yn/(c_nn + c_yn)\n",
    "    condprob_nn = c_nn/(c_nn + c_yn)\n",
    "\n",
    "    # Probabilities of translation absence/presence\n",
    "    prob_trans_y = (c_yy + c_ny)/(c_yy + c_ny + c_yn + c_nn)\n",
    "    prob_trans_n = (c_yn + c_nn)/(c_yy + c_ny + c_yn + c_nn)\n",
    "\n",
    "    # Log probabilities\n",
    "    log_p_yy = max(math.log(condprob_yy) - math.log(prob_trans_y), 0)\n",
    "    log_p_ny = max(math.log(condprob_ny) - math.log(prob_trans_y), 0)\n",
    "    log_p_yn = max(math.log(condprob_yn) - math.log(prob_trans_n), 0)\n",
    "    log_p_nn = max(math.log(condprob_nn) - math.log(prob_trans_n), 0)\n",
    "\n",
    "    return (c_yy*log_p_yy + c_ny*log_p_ny + c_yn*log_p_yn + c_nn*log_p_nn)**1.3\n",
    "\n",
    "\n",
    "# Helper method for llr_score(). Get a dictionary of word:list of indices of sentences where word occurs\n",
    "def get_occurrences(bitext):\n",
    "    occurrences = defaultdict(list)\n",
    "\n",
    "    for (i, (sent_f, sent_e)) in enumerate(bitext):\n",
    "        for w_f in sent_f:\n",
    "            if i not in occurrences[w_f]:\n",
    "                occurrences[w_f].append(i)\n",
    "        for w_e in sent_e:\n",
    "            if i not in occurrences[w_e]:\n",
    "                occurrences[w_e].append(i)\n",
    "\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get word alignment given the parameters obtained from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word alignments\n",
    "def get_alignment(probabilities, bitext):\n",
    "    alignment_pos = []\n",
    "\n",
    "    for (sent_f, sent_e) in bitext:\n",
    "        sent = defaultdict()\n",
    "\n",
    "        for (i, w_f) in enumerate(sent_f):\n",
    "            best_p = 0\n",
    "            best_j = 0\n",
    "\n",
    "            for (j, w_e) in enumerate(sent_e):\n",
    "                if probabilities[(w_f, w_e)] > best_p:\n",
    "                    best_p = probabilities[(w_f, w_e)]\n",
    "                    best_j = j\n",
    "\n",
    "            sent[i] = best_j\n",
    "\n",
    "        alignment_pos.append(sent)\n",
    "\n",
    "    return alignment_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sents = 100000\n",
    "\n",
    "f_data = 'data/hansards.fr' \n",
    "e_data = 'data/hansards.en' \n",
    "\n",
    "# Translation pairs in the form of a list with two sublist of words\n",
    "bitext_f_e = [[sentence.strip().split() for sentence in pair] for pair in islice(zip(open(f_data), open(e_data)), num_sents)]\n",
    "bitext_e_f = [[sentence.strip().split() for sentence in pair] for pair in islice(zip(open(e_data), open(f_data)), num_sents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two word alignment models were trained, with the source and target languages swapped in the second model. The two models then were used to come up with intersected alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and get probability distribution\n",
    "probabilities_f_e = train_alignment(bitext_f_e, 5)\n",
    "probabilities_e_f = train_alignment(bitext_e_f, 5)\n",
    "\n",
    "# Get word alignment\n",
    "alignment_pos_f_e = get_alignment(probabilities_f_e, bitext_f_e)\n",
    "alignment_pos_e_f = get_alignment(probabilities_e_f, bitext_e_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word alignments from the two models trained are intersected to result in a single alignment for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save alignments\n",
    "output = ''\n",
    "for s,s1 in zip(alignment_pos_f_e, alignment_pos_e_f):\n",
    "    for w in s:\n",
    "        if s1[s[w]] == w:\n",
    "            output = output + str(w)+'-'+str(s[w])+' '\n",
    "    output = output + \"\\n\"\n",
    "\n",
    "# Saving the output into a txt file to be used as input for the 'score_alignments.py' script\n",
    "with open(\"output_f_e.txt\", \"w+\") as text_file:\n",
    "    text_file.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs: The file 'score_alignments.py' was changed in order to print only the scores and not the alignment matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.853032\n",
      "Recall = 0.733036\n",
      "AER = 0.203600\n"
     ]
    }
   ],
   "source": [
    "! python3 score_alignments.py -i output_f_e.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
